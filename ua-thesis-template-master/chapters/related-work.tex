\chapter{Related Work}
\label{chapter:related_work}

This chapter establishes the context for the proposed work by reviewing the related work in WiFi based indoor positioning and occupancy detection. 
Besides this, it examines the application of \ac{sgx} in location based systems and analyzes strategies for large data processing within enclaves. 
While nearly identical solutions, combining already existing infrastructure monitoring with hardware enforced privacy, are scarce in the literature, 
distinct bodies of research provide the necessary basis for this dissertation.

The review begins by analyzing technical methodologies for indoor positioning using standard WiFi technologies, 
it then transitions to the critical challenge of user privacy in location analytics. 

The following chapter analyzes \ac{sgx} as a possibility for secure indoor positioning, evaluating its current status and performance in privacy preserving 
location based applications. 
Finishing with the specific analysis of data processing within \ac{sgx}, reviewing architectural strategies for handling large scale sensitive 
data under enclave constraints.

\section{Indoor Positioning System}

As defined by \citet{indoor_positioning_system} an Indoor Positioning System is viewed as 
the grouping of three components: positioning principles and corresponding algorithms, technologies and hardware equipment.
These are considered to have a meaningful impact on the performance of the positioning system (see Figure \ref{fig:struct_ips}).

\begin{figure}
  \includegraphics[width=\linewidth]{figs/indoor_positioning_system.jpg}
  \caption{General structure of the model of an indoor positioning system by \citet{indoor_positioning_system}.}
  \label{fig:struct_ips}
\end{figure}


\subsection{Technologies used for Indoor Positioning System}

There are several technologies used for an Indoor Positioning System, \citet{indoor_positioning_system}
divided them in three categories, this overview has been expanded to include Optical 
and Environmental Sensors, reflecting the methodologies found in research literature,
as shown by Table \ref{table:ips_technologies_category}.

\begin{table}[htbp]
    \centering
    \caption{Indoor Positioning Categories}
    \label{table:ips_technologies_category}
    \begin{tabular}{ l  l }
        \hline
        \textbf{Category} & \textbf{Technologies} \\ \hline
        Radio Frequency (RF) & WiFi \\
                             & Bluetooth Low Energy (BLE) \\
                             & Zigbee \\
                             & Ultra-wide band (UWB) \\
                             & Radio frequency identification (RFID) \\
                             & Indoor Global Navigation Satellite System (GNSS) \\
                             & Frequency modulation radio (FM-radio) \\ \hline
        Non-Electromagnetic Waves & Ultrasound \\
                                  & Geomagnetic Waves \\ \hline
        Full-spectrum light & Range imaging \\
                            & Visible light positioning \\
                            & Laser \\ \hline
        Optical & Cameras / Computer Vision \\
                & Infrared \\ \hline
        Environmental Sensors & CO2 Sensors \\ \hline
    \end{tabular}
\end{table}

\newpage

\section {Wifi for Indoor Positioning}

In the research literature, several terms related to indoor positioning appear interchangeably, such as positioning, localization, detection, counting, and tracking. 
While authors like \citet{24_ZOU2017633} often distinguish these terms based on technical granularity, where localization implies pinpointing specific $(x,y)$ coordinates 
and tracking involves temporal notion, this thesis adopts a broader operational perspective. 

Instead of focusing on the precise coordinate level tracking of targets, the current work prioritizes occupancy detection and crowd estimation in a certain area, 
in this context, the specific terminology is less about the geometric precision of a single user's location and more about the aggregate presence of devices within a defined zone, 
treating location as a categorical state.

To achieve these various levels of granularity, ranging from simple presence detection to precise tracking, researchers leverage different characteristics of the WiFi signal. 
Consequently, the literature presents several distinct methodologies for indoor positioning, each utilizing a specific data metric. 
Prominent examples include the analysis of WiFi probe requests as demonstrated by \citet{23_WANG2018495}, 
the measurement of \ac{rssi} performed by \citet{24_ZOU2017633}, and the more complex \ac{csi} techniques researched by \citet{25_8293759}. 
These approaches, along with others, form the technical basis for the studies reviewed throughout this chapter.

The following chapters will be divided according to the main goal of the Wifi for Indoor Positioning.

\subsection{Energy Savings and Efficiency}

Estimating building occupancy is a necessary step for optimizing building operations, in this scenario
WiFi connection counts are presented as a cost efficient proxy for occupancy when comparing to most common methods, 
even showing a strong correlation with actual people counts as shown by \citet{09_8913341}.

% The following is regarding the article number as 01
% A framework to identify key occupancy indicators for optimizing building operation using WiFi connection count data
In 2021, \citet{01_ALISHAHI2021107936} proposed a framework that uses \ac{ml} alongside with statistical analysis to extract occupancy indicators from WiFi 
connection counts, the authors argued that traditional sensors often suffer from latency, high maintenance costs, and limited scalability. 
In contrast, stated that associated WiFi device counts, which are devices attempting to authenticate with the \ac{ap} not necessarily being able to, as a cost effective proxy for human presence.
The framework showed positive results, however, \citet{01_ALISHAHI2021107936} also highlighted limitations that impact the design of this thesis's methodology. 
It was noted that raw connection counts can possess a degree of noise and require calibration with ground-truth data to account for two sources of error, the stationary devices like 
printers, desktops, and projectors that permanently connect to the network must be filtered out and the device to occupant ratio, which is the variance in the number of 
devices carried by each user. The study emphasizes that these errors become more pronounced at smaller spaces, where attributing a connection to a specific zone is 
difficult without the precise localization data provided by metrics like \ac{rssi}.

% The following is regarding the article number as 02
% Occupancy Detection and People Counting Using WiFi Passive Radar
In the 2020 \ac{ieee} Radar Conference, \citet{02_9266493} presented a methodology 
for people counting based on \ac{pwr}. The authors presented this approach 
to overcome the limitations of standard WiFi sensing, since \ac{rssi} methods are 
prone to unpredictable fluctuations and false positives due to multipath effects, 
and \ac{csi} techniques typically require specific hardware modifications 
or high-rate transmissions that degrade network throughput. 
The overall results presented a high accuracy of 99.54\% for 
tasks of occupancy detection and 98.80\% for people counting. 
Taking into account the positive results, the authors defend that the \ac{pwr} 
system is applicable as it leverages existing commercial WiFi 
\ac{ap}s without requiring any modifications to the WiFi infrastructure or 
additional devices on the network. 
However, this advantage comes with added computational 
complexity, as the system relies completely on signal processing.

% The following is regarding the article number as 03
% WiFi based occupancy detection in a complex indoor space under discontinuous wireless communication: A robust filtering based on event-triggered updating
\citet{03_WANG2019228} approached the challenge of discontinuous communication in mobile devices, where smartphones suspend WiFi transmission to conserve battery, 
causing users to disappear temporarily from network scans. To maintain accuracy during these periods, the authors developed an event triggered 
framework that estimates occupancy based on entry and exit events. 
The framework also integrates a location filter using \ac{rssi} thresholds to discard devices located outside the target zone by applying a study of the mean values of the measured data in inside 
and outside positions which could be helpful for the current work, and a non-human filter to exclude stationary equipment, such as printers, via \ac{mac} address analysis. 
The authors also acknowledge limitations such as the reliance on \ac{rssi} thresholds restricts the system to zone level accuracy, the behavior 
of smartphones suspension of data transmission and the detection errors from user behavior, 
like occupants carrying multiple devices or separating from their smartphones.

% The following is regarding the article number as 04
% Effectiveness of using WiFi technologies to detect and predict building occupancy
In 2017, \citet{04_OUF2017005} presented a case study to demonstrate the effectiveness of using WiFi to detect occupancy as opposed to the more common $CO_2$ sensors. 
To allow this comparison, the authors monitored WiFi connection counts and 
$CO_2$ at the same time, observing concentration levels in a university classroom over one week, using manual occupant counts as ground truth. 
The analysis revealed that WiFi counts served as a more suited predictor of occupancy, showing a statistical correlation of $r=0.839$ when $CO_2$ levels show $r=0.728$.
Furthermore, the authors highlighted that while $CO_2$ sensors suffered from a detection lag of approximately 20 minutes and susceptibility to non-occupancy related fluctuations, WiFi data 
provided a more accurate, real time proxy for occupancy with the added benefit of utilizing existing infrastructure without additional cost.

% The following is regarding the article number as 13
% Classroom Occupancy-based Human Resource Optimization using Sensor- and WiFi-based Location Tracking
In a Master's thesis, \citet{13_thesis} developed a framework for optimizing human resource allocation, directed for cleaning and maintenance, 
this was done by comparing three occupancy detection models: static university course schedules, thermal occupancy sensors, and WiFi location tracking. 
The study highlighted that while schedule based models are often inaccurate due to student absenteeism, thermal sensors provided the highest accuracy of approximately 
98\% by counting heat signatures at doorways. 
However, the author emphasized the negative considerations on the scalability of thermal sensors, due to a large installation cost. 
In contrast, the WiFi based model, utilizing the existing network achieved a comparable accuracy of roughly 90\% with zero additional 
infrastructure costs. 
A supporting survey within the study validated the viability of this approach, revealing that 95.2\% of campus users carried smartphones, 
with 90.5\% actively logged into the university network, confirming that WiFi connection counts serve as a reliable, cost-effective proxy for real time occupancy.

% The following is regarding the article number as 16
% Classroom Automation Using RSSI
In 2019, \citet{16_8938387} proposed a model for an occupancy monitoring system based on the \ac{rssi} detected by low-cost microcontrollers. 
To address the instability of wireless signals, the system employs a mean algorithm, which triggers an occupancy state only when the average \ac{rssi} over 
seven iterations dips below a calibrated threshold. 
Experimental trials demonstrated a high detection accuracy of 95\%, approximately one error every 20 minutes, but only within a limited 3 meter line of sight range. 
The authors noted that beyond this 3 meter radius, the accuracy degrades due to multipath propagation. 
\footnote{Phenomenon in wireless communication where a transmitted signal reaches the receiver antenna through multiple paths due to reflections and scattering 
from environmental objects, resulting in different signal copies with varying attenuation, phase shifts, and time delays as defined by \citet{KALUUBA2006621}}
This observation is relevant to the current thesis, as it highlights the physical limitations of \ac{rssi} based ranging in indoor environments.

\subsection{Behavioral Monitoring}

% The following is regarding the article number as 05
% TRACKING INDOOR LOCATION , MOVEMENT AND DESK OCCUPANCY IN THE WORKPLACE
A case study performed by \citet{05_CRACKED_LABS} in 2024 analyzed the privacy implications of existing technologies for behavioral monitoring and profiling. 
The report examined solutions from major vendors such as Cisco, Juniper, Spacewell, and Locatee, identifying a trend where 
workplace infrastructure is used for tracking user behavior. 
Specifically in Section 3.2, the study focuses on Cisco, the manufacturer of the devices generating the logs utilized in this dissertation. 
The report shows a product called Cisco Spaces, a cloud platform that processes large amounts of data to profile user behavior. 
For user classification, the report notes that the system categorizes persons into groups like employee, student or guest based on the SSID category, 
this points that the system identifies the type of user based of the WiFi network the user connects to, allowing for distinct tracking of 
different user groups and their behaviors.

% The following is regarding the article number as 10
% EDUM: Classroom Education Measurements via Large-scale WiFi Networks
In 2016, \citet{10_10.1145/2971648.2971657} proposed the EDUM (EDUcation Measurement) system to characterize educational behaviors using data collected from large-scale WiFi infrastructures, 
analyzing students punctuality based on longitudinal WiFi connection traces and to assess lecture attractiveness and student distraction.
The system utilizes the mobile phone's interactive state, the screen on/off status, at a per minute basis.
Deployed at Tsinghua University with approximately 700 student volunteers and 2,800 \ac{ap}s, the study provided results that revealed a negative correlation between high mobile phone usage during 
class and academic performance (GPA), and confirmed that students seated in the back rows exhibit significantly higher distraction levels than those in the front.

% The following is regarding the article number as 11
% Integrating Indoor Localization Technologies for Enhanced Smart Education: Challenges, Innovations, and Applications
Later in 2025, \citet{11_11030449} realized a study to investigate indoor location technologies for future integration in Smart Education (SE) environments, the authors 
reviewed several technologies, as mentioned earlier on this chapter, but for the sake of the thesis the focus will be toward WiFi. 
The authors identified WiFi as an accessible technology for SE, citing its availability in educational institutions and the  
connectivity provided by networks like eduroam, the one used on the present thesis. 
Regarding its capabilities, the study showed the potential of the \ac{ieee} 802.11mc standard, which allows for ranging, within approximately 1 meter, and preserves user 
privacy with calculations on the client device side. 
However, in their experimental \ac{poc} for automatic attendance, the WiFi approach achieved an accuracy of 93.77\% using a regression model, 
it was outperformed by 5G (97.21\%), leading the authors to conclude that while WiFi is a useful tool due to it's low cost and presence, 
a fusion of technologies provides the most robust solution for critical attendance monitoring.

\subsection{Occupancy Monitoring}

% The following is regarding the article number as 09
% Role of Campus WiFi Infrastructure for Occupancy Monitoring in a Large University
In the 2018 IEEE International Conference on Information and Automation for Sustainability (ICIAfS), \citet{09_8913341} 
proposed a study to assess the feasibility of using WiFi \ac{ap} infrastructure for room level occupancy monitoring across the University of New South Wales campus, a scenario similar to that of this thesis. 
The study had a duration of four weeks across rooms with varying numbers of \ac{ap}s, comparing WiFi data against beam counter sensors and ground truth enrollment numbers. 
To account for transient users, passing by, connecting to the \ac{ap}s, connections lasting less than five minutes were filtered out. 
The results indicated that the WiFi method achieved a stronger correlation with actual occupancy ($R=0.85$) compared to the beam counters ($R=0.68$).

% The following is regarding the article number as 06 and 07 (precursor)
% Modeling Classroom Occupancy Using Data of WiFi Infrastructure in a University Campus
Later in 2022, \citet{06_9750047} published in the \ac{ieee} Sensors Journal a \ac{ml} framework to infer classroom occupancy, 
sharing the same goal as the current work but employing standard statistical modeling. 
The authors utilized daily WiFi logs from the university's IT department, a scenario identical to this dissertation, comprising 
data from 70 \ac{ap}s including \ac{uu}, \ac{mac} address, event timestamps, and \ac{ap} names. 
Besides the similar data source, \citet{06_9750047} identified critical limitations in using raw logs, 
such as the overlapping coverage of \ac{ap}s (where a student inside a room connects to a hallway \ac{ap}), 
the presence of "bystanders", and the variability of multiple device connections per user. 
Ultimately, the framework achieved a symmetric Mean Absolute Percentage Error of 13.1\%, a result comparable to dedicated beam counter sensors, 
this once more demonstrated that existing WiFi infrastructure can result in accurate occupancy estimation 
with no additional deployment costs, only computing costs.

% The following is regarding the article number as 14_02
% Localization and Counting of Indoor Populations on a University Campus using Wi-Fi Connection Logs and Floor Plans
In 2022, for a Master's thesis, \citet{14_02_thesis} proposed the "Building Floor Zone" technique to improve WiFi counting precision without requiring new hardware. 
The methodology involved mapping \ac{ap}s to specific zones based on room numbering and assigning hallway \ac{ap}s to the center of adjacent rooms, in similarity with the present thesis. 
Experimental analysis confirmed that this approach resulted in a higher statistical correlation with schedule based ground truth compared to standard floor level aggregation. 
An interesting mention is that the study found that counting all unique connections provided better accuracy than filtering for long duration sessions, challenging the assumption that 
transient users are merely noise. 

% The following is regarding the article number as 08
% Attendance monitoring in classroom using smartphone & Wi-Fi fingerprinting
Earlier in 2016, \citet{08_7814796} proposed an attendance system that combines facial recognition for user authentication with WiFi network analysis to verify the student's location. 
While the authors acknowledged methods like trilateration 
\footnote{Trilateration is a geometric method of determining location by measuring distances from at least three known reference points using signal strength.}, 
due to signal interference adopted a fingerprinting approach using the \ac{ml} algorithm. 
Regarding the results, the system demonstrated positive precision, achieving a positioning error between 1 and 2.5 meters. 
In practical testing, this methodology identified whether a student was inside the target classroom 94\% of the time.

% The following is regarding the article number as 14
% WiFi Received Signal Strength (RSS) Based Automated Attendance System for Educational Institutions
\citet{14_10_1145_3704522_3704523} presented a smartphone based attendance system utilizing WiFi signal strength for indoor localization. 
As noted in previous works, distinguishing user presence within confined boundaries, like a specific room, is challenging due to signal fluctuations. 
To address this, the authors employed a zone based fingerprinting approach, dividing the space into virtual grids and using machine learning to classify them. 
A valuable insight for this thesis is the authors explicit classification of signal quality, which categorizes \ac{rssi} values into ranges according to signal strength, 
something that could be necessary in the current work. 
The authors system achieved 100\% accuracy in one test room and 92\% in another. 
Furthermore, the study demonstrated significant robustness, the accuracy remained stable even when individual \ac{ap}s were removed or 
when different smartphone models were used.

\subsection{Fingerprinting}
% The following is regarding the article number as 18
% WIFI FINGERPRINT INDOOR POSITIONING SYSTEM USING PROBABILITY DISTRIBUTION COMPARISON
In a study focusing on probabilistic localization, \citet{18_6288374} developed a WiFi fingerprinting system that utilizes probability distribution comparisons 
rather than simple \ac{rssi} averaging. Crucially for the context of this thesis, the methodology also used an offline phase to construct a radio map, 
a database where fingerprints were manually collected at several known rooms throughout the building. 
During the offline phase, the authors collected 100 \ac{rssi} samples at each reference point to estimate the signal strength probability 
distributions for every visible access point. This data collection process demonstrates the significant calibration effort, necessary in fingerprinting approaches. 
While their method achieved a median positioning error of 2.4 meters, the requirement to build and maintain such a detailed radio map highlights the scalability challenges 
that the passive, infrastructure based approach proposed in this current work seeks to eliminate.

% The following is regarding the article number as 19
% WIFI FINGERPRINT INDOOR POSITIONING SYSTEM USING PROBABILITY DISTRIBUTION COMPARISON
Similarly, in 2020, \citet{19_NINH2020238} proposed a random statistical method for indoor positioning that relies on the same two phase architecture common to 
fingerprinting solutions. The system explicitly distinguishes between an offline handling process, where a large number of WiFi signals are collected at specific 
reference points to create a database, and an online positioning process that uses the Mahalanobis distance to match live user data against this stored radio map.

\section{Approaches to Privacy in Indoor Positioning Literature}

The domain of privacy in data processing is made of several methodologies, ranging from approaches like k-anonymity to semantic 
definitions such as differential privacy. 
While these approaches are fundamental to the field, a comprehensive analysis of their details falls outside the scope of this dissertation. 
Instead, this section provides a high-level categorization of the privacy paradigms observed specifically within the context of indoor positioning literature. 
The objective is not to evaluate the cryptographic strength of these mechanisms, but to contextualize how current indoor positioning systems attempt to 
balance utility with user privacy, highlighting the limitations that motivate the adoption of a \ac{tee} approach.

The ubiquity of WiFi networks as a sensing infrastructure presents a fundamental problem, the same data that allows occupancy monitoring 
also introduces significant privacy risks for the individuals being tracked. As noted in the previous sections, transforming a standard wireless network into a 
soft sensor involves analyzing device footprints, specifically \ac{mac} addresses and signal characteristics, which can serve as strong identifiers of specific individuals.

Consequently, the academic literature demonstrates a variety of methodologies designed to balance the trade off between service utility and user privacy. 
These approaches range from data minimization strategies, that avoid collecting unique identifiers, to more complex anonymization schemes like hashing 
and k-anonymity. 
However, as the demand for room level precision increases, so does the inadequacy of traditional methods. 

This section reviews these privacy preserving strategies, categorizing them into distinct paradigms found in the literature,  
omission of privacy mechanisms, where technical feasibility takes precedence,  
data aggregation and minimization, where sensitive data is aggregated at the source,  
anonymization and pseudonymization, where identifiers are masked, 
institutional compliance and ethical clearance, relying on governance frameworks and volunteer based or opt-in models. 

\subsection{Omission/Inexistence of Privacy Mechanisms}

\citet{03_WANG2019228} focused on the technical application of detecting inactive smartphones to improve detection accuracy. 
While the system utilizes \ac{mac} address analysis to filter non-human devices, the study does not detail any mechanisms for anonymizing these addresses or 
protecting the identity of the smartphone owners.

Furthermore, \citet{05_CRACKED_LABS} provided an analysis of commercial indoor positioning systems, identifying a lack of 
privacy by design in several applications. The report shows that these platforms often prioritize profiling and categorizing users into groups like employees or 
students, over data protection, allowing for the tracking of individual movements without obfuscation or user optional mechanisms.

\citet{09_8913341} conducted a validation of WiFi occupancy sensing by benchmarking it against hardware counters across a university campus. 
The study focused on the utility of the metadata, like user's \ac{mac} address which can endanger students privacy, since 
the authors did not detail privacy preserving architectures, it leads to the assumption of inexistence of privacy preserving mechanisms.

\subsection{Data Aggregation and Minimization}

\citet{01_ALISHAHI2021107936} adopted a data minimization strategy by relying only on aggregated connection counts per \ac{ap}. 
By converting raw network logs into numerical totals before analysis, the framework inherently discards individual identifiers, 
ensuring that no unique user data is retained.

\citet{02_9266493} took the concept of data minimization to the physical layer by employing a device free approach known as Passive WiFi Radar. 
Instead of decoding data packets or logging \ac{mac} addresses, this method analyzes signal reflections caused by moving bodies. 
Consequently, the system avoids collecting any digital identifiers, making the data inherently anonymous and decoupling the occupancy detection from the users' 
personal devices.

Similarly, \citet{04_OUF2017005} employed an aggregation strategy to validate WiFi sensing against environmental benchmarks. 
By utilizing the total number of connections as a bulk metric to correlate with $CO_2$ levels, the authors treated the crowd as a single entity. 
This approach avoids the privacy difficulties of tracking, as the system monitors the state of the room and not the behavior of the individuals within it.

\citet{13_thesis} demonstrated a resource optimization framework that relies on aggregated occupancy density. 
By only using bulk connection counts directly from the university's central IT department, rather than logging individual devices, the system calculates the "usage intensity"  
of classrooms.

\subsection{Anonymization and Pseudonymization}

\citet{14_02_thesis} implemented a form of pseudonymization to mitigate the risks of long-term profiling. 
In this study, the unique identifiers were masked using a hashing algorithm that was reset every 24 hours, something similar 
to what will be done during the development process of this dissertation.

\subsection{Institutional Compliance and Ethical Clearance}

\citet{06_9750047} addressed the privacy implications of tracking students by operating under a governance framework, since 
the study obtained formal ethical clearance from the university.

\subsection{Volunteer Based Model or Opt-in Model}

\citet{08_7814796} implemented a privacy model based on user interaction. In their system, attendance is not monitored passively, instead, students must actively engage 
with a smartphone application to capture a facial scan and submit their WiFi fingerprint, which falls in the category of an opt-in, ensuring that location data is only 
transmitted with the user's direct consent and knowledge.

\citet{10_10.1145/2971648.2971657} employed a volunteer based model to justify the collection of highly granular behavioral data. In their "EDUM" system, 
the researchers recruited approximately 700 students who consented to having their WiFi traces and mobile application usage monitored. 

\citet{11_11030449} highlighted the privacy advantages of the IEEE 802.11mc standard, which shifts the location calculation to the client device. 
To demonstrate this architecture, the authors developed a mobile application, by requiring students to actively install and engage with this software to register their 
presence, the system uses an opt-in model.

Likewise, \citet{14_10_1145_3704522_3704523} developed a smartphone based attendance system that leverages \ac{rssi} zoning to verify student presence. 
Since the primary utility is the validation of attendance records using the students smartphone, the architecture operates on an opt-in model where 
students consent to the tracking of their devices.

%\subsection{Summary}

%Existing literature relies on data minimization or obfuscation techniques to achieve privacy. 
%However, these approaches introduce a trade-off, to increase privacy, the granularity of the data must be decreased.  
%For the present use case, where precision must be maintained, this trade-off is not acceptable, consequently, this work moves away 
%from statistical obfuscation and focuses on hardware-enforced confidentiality with \ac{sgx}, avoiding algorithms that add noise, allowing 
%for the processing of exact data while maintaining it's confidentiality and integrity.

\section{Previous Works with \ac{sgx} in Indoor Positioning}
While the literature regarding the specific application of \ac{sgx} to indoor positioning remains limited, a select number of 
studies have established a base foundation for this approach.

% The following is regarding the article number as 20
% Privacy Protection in 5G Positioning and Location-based Services Based on SGX
To address the privacy concerns associated with collecting user location data, \citet{20_10.1145/3512892} proposed a trusted computing framework based on \ac{sgx}. 
The authors stated that traditional techniques like k-anonymity or encryption, may include computational overheads or 
require dependencies on a \ac{ttp}.
In contrast, their work demonstrates that SGX allows a privacy scheme, by processing sensitive location data within a hardware protected 
enclave, the system ensures that raw identity information remains inaccessible to the operating system or 
the service provider, allowing secure analysis without exposing individual user data. 
This approach validates the architectural choice in this thesis to utilize SGX enclaves for processing sensitive WiFi logs, ensuring compliance with privacy 
standards while maintaining system performance.

% The following is regarding the article number as 21
%Privacy-Preserving Location-Based Services by using Intel SGX
Complementing the architectural advantages mentioned in the previous work, \citet{21_Kulkarni:15319} provided an evaluation of \ac{sgx} for location based services, 
explicitly comparing it against traditional k-anonymity techniques. The study highlighted a trade off in privacy handling, 
that traditional obfuscation methods degrades service accuracy to achieve privacy. 
In contrast, their experiments demonstrated that an \ac{sgx} based approach provides better result accuracy because the computation occurs on exact data within the secure 
enclave, protected from the host system.
Furthermore, the authors quantified the performance cost of this security, finding that \ac{sgx} introduces only a small penalty compared to bare metal implementation, due to 
the one time events such as the enclave creation, copying data, sealing and unsealing.
This finding is important for the current thesis, as it validates that shifting the occupancy estimation logic into an \ac{sgx} enclave is a viable strategy that secures 
student data without compromising the real time performance or the accuracy of the occupancy counts. 

\section{Data Processing in \ac{sgx}}

Processing large scale data within \ac{sgx} introduces memory challenges, primarily due to the limited size of the \ac{epc} and the high cost of 
transitions between trusted and untrusted memory. 
Consequently, standard data processing frameworks cannot be directly ported to enclaves without significant performance overhead.
To address these limitations, the state-of-the-art literature proposes various architectural strategies, 
ranging from data partitioning and streaming to hardware offloading and oblivious execution.

It is important to note that while some of the discussed frameworks utilize alternative trusted hardware, their architectural 
principles for mitigating memory constraints are applicable to \ac{sgx} enclaves.
The following subsections categorize these frameworks by their application domain, reviewing solutions for general-purpose processing, secure analytics, 
deep learning acceleration, and distributed federated learning.

\subsection{General Purpose Data Processing}
% The following is regarding the article number as 01 in the SGX folder
\citet{s01_7163017} presented \ac{vc3}, a distributed MapReduce model 
\footnote{Programming model for processing large data sets, users write map and reduce functions, and the execution of both functions is automatically parallelized and distributed, as defined by \citet{MapReduce}}
designed to address these limitations by strictly minimizing the \ac{tcb}.
Unlike systems that attempt to execute entire legacy applications or libraries from the \ac{os} inside an enclave, \ac{vc3} adopts a partitioned architecture, where 
the heavy lifting of job scheduling and data storage remains in the untrusted Hadoop (open source framework for distributed storage and processing of large datasets). 
Only the specific map and reduce functions, along with a minimal cryptographic shim, are loaded into the protected enclave.
To cope with the memory constraints of the enclave, \ac{vc3} relies on a streaming data model. 
Encrypted data is ingested in input splits and processed within the enclaves heap, and the results are encrypted and then streamed out. 
To mitigate the performance overhead of \ac{sgx} context switches, between \texttt{ECalls} and \texttt{OCalls}, \ac{vc3} utilizes a shared memory region for communication and implements aggressive batching. 
By processing key value pairs in batches, rather than individually, the system reduces the frequency of expensive enclave transitions.
Furthermore, to avoid the memory footprint of standard libraries, \ac{vc3} uses a custom runtime library and heap allocator, 
ensuring that the limited secure memory is dedicated primarily to the user's data and logic.

\begin{figure}
  \begin{center}
  \includegraphics[scale=0.7]{figs/mapReduceSteps.png}
  \caption{Steps of MapReduce with mappers (M) and reducers (R), image by \citet{s01_7163017}.}
  \label{fig:mapReduce_steps}
  \end{center}
\end{figure}

% The following is regarding the article number as 02 in the SGX folder
In contrast to the streaming model employed by MapReduce frameworks, \citet{s02_8418608} proposed EnclaveDB, a database engine designed to minimize the 
overhead of data processing by keeping all sensitive state resident within the enclave memory. 
Leveraging the Hekaton, a \ac{sql} engine, EnclaveDB avoids the cost of disk \ac{io} by ensuring that encryption and decryption occur only at the 
transaction boundaries rather than at the page level during execution. 
To reduce the \ac{tcb} and optimize memory usage, the system adopts a pre-compiled execution model, complex query parsing and optimization are 
offloaded to a trusted client, and only the resulting native machine code is deployed to the enclave. 
This architecture reduces the frequency of context switches, a known performance bottleneck in \ac{sgx}, by executing entire transactions 
within the protected region without passing control back to the untrusted host until the transaction commits. 
Furthermore, to address the integrity of persistent data without the high memory cost of maintaining, a hash tree over the transaction log, 
EnclaveDB implements a lightweight protocol using hardware based counters and serialization points to guarantee the data updates and prevent rollback attacks.

\subsection{Secure Analytics and Access Patterns}

Advanced analytics and \ac{ml} algorithms rely on matrix operations, however, executing these workloads within \ac{sgx} introduces a vulnerability, 
standard algorithms show memory access patterns. 
These allow privileged adversaries to infer sensitive information from the execution trace, even when the memory contents are encrypted. 

% The following is regarding the article number as 03 in the SGX folder
In 2017, \citet{s03} introduced SGX-BigMatrix, a framework for performing secure matrix operations on encrypted data. 
Recognizing that large scale matrices often exceed the limited \ac{epc} capacity, the authors developed a BigMatrix abstraction that partitions data into 
fixed size, encrypted blocks. 
These blocks are dynamically loaded into the enclave for processing and evicted to untrusted memory via a software managed swapping mechanism, 
effectively bypassing the performance overhead of the operating system's paging. 
Crucially, to address the vulnerability of side-channel attacks, SGX-BigMatrix enforces data oblivious execution, 
by utilizing vectorized oblivious primitives and a specialized compiler to manage block transitions, the framework ensures that the sequence of 
memory accesses remains independent of the sensitive data, preventing adversaries from inferring information through memory access traces.

% The following is regarding the article number 04 in the improvements folder
In the domain of privacy-preserving \ac{ml}, \citet{s04} addressed the challenge of side-channel leakages in SGX-based data processing. 
The authors stated that although SGX allows for memory confidentiality, standard ML algorithms show data-dependent memory access patterns that can be observed by a 
privileged attacker to infer sensitive information, to mitigate this, they proposed data-oblivious for several \ac{ml} algorithms.
Instead of standard conditional branches, which leak information through the instruction trace, the authors implementation utilizes oblivious primitives based on conditional move 
instructions and vectorized memory operations. 
This ensures that the execution trace depends solely on public parameters, such as the dataset size, rather than the private input data. 
Their evaluation demonstrated that this hardware-assisted approach is significantly more efficient than purely cryptographic alternatives, 
such as homomorphic encryption, enabling the training of models on realistic datasets with manageable overhead.

% he following is regarding the article number 05 in the improvements folder
Complementing the discussion on performance trade-offs by \citet{s04}, \citet{s05} argued that data-oblivious techniques, while adding security guarantees, 
often lead to performance overheads for analytics. 
To address this issue, the authors proposed a randomization-based defense strategy, to do this, instead of eliminating data-dependent access patterns, 
which requires expensive actions, their approach adds noise into the memory access traces. 
Specifically, the noise is introduced with the generation of dummy data instances that mimic the valid dataset, these are created by selecting random feature values uniformly distributed within 
the ranges from the original data, ensuring they possess no distinguishing characteristics. 
These dummy records are then shuffled with the real user data using a sorting network based on random keys generated via SGX's hardware random number generator function. 
By masking the true data access sequence with random memory operations, this method prevents side-channel attackers from inferring sensitive information with high confidence. 
This introduces a strategic trade-off between privacy and efficiency, with the strict determinism of data-obliviousness in favor of a probabilistic protection model, 
the system achieves significantly higher computational throughput, making it more suitable for large-scale data analytics tasks.

\subsection{Deep Learning and Hardware Acceleration}

The deployment of \ac{dnn}s in trusted environments faces the difficulty of the conflict between the computational demands of deep learning and the hardware limitations of standard enclaves. 
\ac{sgx} is \ac{cpu}-bound and lacks direct access to trusted accelerators, such as \ac{gpu}s, creating a bottleneck for matrix operations. 
Furthermore, the memory footprint of modern models and intermediate activations exceeds the trusted capacity of the \ac{epc}. 

% The following is regarding the article number 06 in the improvemts folder
Addressing the hardware limitations of executing neural networks within \ac{cpu}-bound enclaves, in 2019 \citet{s06} proposed Slalom, a framework for verifiable and private execution. 
Recognizing that the lack of trusted \ac{gpu} support in \ac{sgx} creates a significant bottleneck for heavy matrix operations, the authors introduced a hybrid execution model. 
In this approach, the enclave delegates work to a remote or local \ac{gpu} to use its processing power, but this delegation does not align with the confidential necessities, so to ensure security, 
it uses a verification mechanism based on Freivalds' algorithm, that allows the \ac{tee} to check the integrity of the \ac{gpu}'s output without re-executing the full computation. 
For privacy-preserving inference, the system utilizes input blinding techniques, ensuring that the data processed by the untrusted \ac{gpu} remains opaque, this decouples 
the security logic from the bulk computation, demonstrating a viable path for high-performance deep learning in confidential computing.

% The following is regarding the article number 07 in the improvemts folder
Addressing data processing under severe memory constraints, \citet{s07} proposed DarkneTZ, a framework designed to execute \ac{dnn} within the limited trusted memory of edge devices. 
Although designed for ARM TrustZone on edge devices rather than Intel \ac{sgx}, their architectural approach is relevant to solving \ac{epc} limitations.
Instead of processing the entire computation inside the \ac{tee}, DarkneTZ employs a model partitioning strategy. 
The system splits the data flow, the initial, expensive feature extraction layers are processed in the untrusted environment, while the intermediate activations are securely transferred to the \ac{tee} for the final classification layers. 
Within the enclave, the processing logic includes a data sanitization step, by normalizing the output confidence scores, before returning them to the untrusted OS. 

% The following is regarding the article number 08 in the improvements folder
To address the bottleneck of processing \ac{dnn} training workloads within trusted hardware, \citet{s08} proposed GOAT, a system that restructures the data processing pipeline through secure outsourcing. 
Instead of processing the entire dataset within the enclave, GOAT delegates the matrix operations of forward and backward propagation to an untrusted \ac{gpu}. 
To maintain data integrity during this external processing, the system employs an asynchronous probabilistic verification strategy, the \ac{tee} acts as an auditor, selecting data batches to re-process internally. 
By comparing these trusted computations against the \ac{gpu}'s outputs in parallel with the main training loop, the system statistically guarantees the correctness of the outsourced processing without stalling the data flow, 
bridging the gap between the integrity of \ac{tee}s and the throughput of hardware accelerators.

% The following is regarding the article number 11 in the improvements folder
Expanding the scope of secure data processing beyond fixed \ac{cpu} instruction sets, \citet{s11} introduced MeetGo, a \ac{tee} architecture designed for \ac{fpga}s. 
In this paradigm, data processing is not defined by software instructions but by reconfigurable hardware circuits. 
MeetGo utilizes \ac{dpr} to instantiate isolated hardware modules, like the enclave, on demand within the \ac{fpga} fabric. 
The processing pipeline is controlled by a hardware-based security manager, which performs line-rate decryption and encryption of data streams entering and leaving the processing modules. 
This architecture allows for high-throughput, custom hardware acceleration of sensitive workloads while enforcing memory isolation through specialized hardware monitors, 
effectively preventing the user-defined logic from accessing unauthorized memory regions during execution, but this comes with the additional cost of the \ac{fpga} hardware.

% The following is regarding the article number 12 in the improvements flder
While frameworks like DarkneTZ address memory limitations by offloading layers to untrusted hardware, \citet{s12} proposed optimization techniques 
designed to keep the inference execution within the enclave. 
Identifying that the standard execution flow of convolutional layers triggers page thrashing, the authors introduced y-plane partitioning. 
This strategy divides the input and output tensors into horizontal bands that fit within the enclave's secure memory, ensuring that the working set 
remains resident in the secure cache. 

\subsection{Distributed and Federated Learning}
In the context of federated learning, where a central server aggregates model updates from numerous remote clients, memory constraints become even more 
noticeable due to the high dimensionality of modern models. 

% The following is regarding the article number 10 in the improvements folder
\citet{s10} proposed SGX-FL to address the performance bottleneck of aggregating gradient vectors within \ac{sgx} by modifying the data processing logic to exploit sparsity. 
Instead of processing full dense updates, which often trigger severe page thrashing in the \ac{epc}, the authors implemented a Top-$k$ gradient selection algorithm directly within the enclave. 
This technique filters incoming data, aggregating only the most significant gradients while discarding negligible values, thereby drastically reducing the memory working set. 
Furthermore, the system optimizes the remaining computation through block-wise data loading and double buffering, ensuring that the processing of gradient blocks aligns with the \ac{CPU} cache size to minimize memory access latency during the secure aggregation phase.

% The following is regarding the article number 09 in the improvements folder
Scaling data processing beyond the limits of a single trusted enclave, \citet{s09} introduced SecureTF, a mechanism for distributed machine learning execution. 
This mechanism partitions the data processing workflow into a parameter servers architecture, where the computational load is distributed across multiple enclaves, workers compute gradients on private data, 
while parameter servers aggregate these updates to refine the global model. 
To handle the intensive memory demands of tensor operations that typically exceed the trusted memory of the \ac{epc}, the system uses a shielded execution runtime, in this case SCONE
\footnote{A secure container mechanism for Docker that uses the \ac{sgx} trusted execution support of Intel \ac{cpu}s to protect container 
processes from outside attacks, by \citet{scone}.}
, to manage secure paging and encrypted I/O transparently during execution. 
This allows for the stateful processing of large-scale datasets and complex computation graphs across a cluster of TEEs, ensuring that data remains encrypted not only at rest but also throughout the entire distributed calculation pipeline.

% The following is regarding the article number 14 in the improvements folder
In the area of federated learning, secure aggregation typically relies on cryptographic operations such as encryption, which introduces computational overhead. 
\citet{s14} proposed PPFL, a framework that shifts the processing from cryptographic computation to hardware-based isolation. 
By utilizing the \ac{tee} as a trusted aggregator, the system performs model updates in plaintext within the secure memory, avoiding the performance penalties of operations on ciphertext. 
To optimize the data flow against network latency and client variability, PPFL implements a greedy grouping strategy within the aggregation logic, 
this mechanism batches and processes incoming gradients from clients without waiting for stragglers, streamlining the training pipeline and reducing the total convergence time compared to cryptographic approaches.

% The following is regarding the article number 13 in the improvements folder
\citet{s13} proposed FLATEE, a framework that leverages \ac{tee}s to replace expensive cryptographic protocols in federated learning. 
By performing model aggregation within enclaves at the server side and incorporating several algorithms for data aggregation and resilience, 
the system ensures privacy and resilience against poisoning attacks while reducing training and communication latency compared to traditional crypto-based approaches.

% The following is regarding the article number 15 in the improvements folder
Addressing the vulnerability of gradient linkability, \citet{s15} introduced a shuffling mechanism within the \ac{tee} processing pipeline by the name of ShuffleFL. 
Recognizing that the sequence of data arrival and memory access patterns can reveal the source of a model, even when the payload is encrypted, the proposed system includes 
a randomization layer before aggregation. 
Incoming gradients are buffered and subjected to a random permutation inside the enclave, decoupling the gradient values from their identifiers, 
ensuring unlinkability, preventing the server from correlating specific model updates with their originating clients based on communication metadata or execution timing.

% The following is regarding the article number 16 in the improvements folder
\citet{s16} identified that data-dependent optimizations introduce side-channel vulnerabilities. 
Processing sparse gradients reveals memory access patterns, specifically, the indices of non-zero updates, which can allow an adversary to 
infer feature distributions. 
To address this, the authors proposed Olive, a framework that reconciles efficiency with security through oblivious sparse aggregation, so 
instead of directly accessing sparse indices, the system employs hardware oblivious primitives to align and aggregate gradients. 
By ensuring that the memory access trace remains independent of the actual values and indices of the gradient updates, 
it closes the leakage channel associated with data processing, with the additional cost of reintroducing some computational overhead 
compared to simple sparse aggregation.

% Global Summary
\section{Summary}
The review of the literature reveals a gap in the intersection of indoor positioning and privacy-preserving technologies. 
The dependency on logs introduces challenges that require the usage of filters, as identified in the reviewed literature, 
occupancy is affected by stationary devices, transient users or bystanders who are passing by the access point's range, 
and discontinuous communications from mobile devices entering power-saving modes. 

Although literature validates WiFi connection logs as an effective and scalable proxy for occupancy counting, 
reviewed implementations face a dilemma, overlook user privacy to prioritize utility or rely on opt-in models 
that introduce scalability and accuracy issues.

\ac{tee}, such as Intel \ac{sgx}, appears as a possible solution to this limitation, allowing for the processing of sensitive data 
without exposing it to the infrastructure. 
However, \ac{sgx} in large-scale data processing introduces challenges, due to the limited \ac{epc} size and the overhead of 
context switching between trusted and untrusted environments.

While frameworks like \ac{vc3} and EnclaveDB address large-scale data processing, and recent systems such as Slalom, DarkneTZ, or PPFL focus on heavy 
\ac{ml} workloads and federated aggregation, they introduce complexity and hardware dependencies. 
These approaches are not suited for the objectives of this dissertation, which requires a lightweight monitoring system capable of handling continuous streams of WiFi logs with minimal overhead.

Consequently, this thesis proposes an architecture that uses the security mechanisms of \ac{sgx} but implements a custom memory management strategy. 
